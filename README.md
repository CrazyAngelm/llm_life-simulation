# ğŸš€ LLM Life Simulator - Quick Start

## ğŸ“ Project Structure
```
life_simulator_mvp/
â”œâ”€â”€ config.py            # Simulation settings
â”œâ”€â”€ models.py            # NPC and Location classes
â”œâ”€â”€ llm_clients.py       # Ollama & DeepSeek integration
â”œâ”€â”€ simulator.py         # Core simulation logic
â”œâ”€â”€ main.py              # Entry point
â”œâ”€â”€ requirements.txt     # Dependencies
â””â”€â”€ README_QUICK_START.md # This guide

# Generated at runtime:
â”œâ”€â”€ world_state.json   # Current world state
â””â”€â”€ chronicles.md      # Narrative chronicles
```

## âš¡ Quick Start (5 minutes)

### 1. Install dependencies
```bash
python -m venv venv
.\venv\scripts\activate
pip install -r requirements.txt
```

### 2. Launch Ollama
```bash
# In a separate terminal:
ollama serve
ollama pull qwen2.5:3b
```

### 3. Configure DeepSeek API (optional)
Edit `config.py`, line:
```python
"deepseek_api_key": "your-key-here"  # Replace
```

### 4. Run the simulation
```bash
python main.py
```

## ğŸ¯ What It Demonstrates

### AI AGENT aspects
- âœ… **10 autonomous NPCs** with state (health, energy, mood, hunger)
- âœ… **Roles & behaviour**: king, peasants, hunters, sage, merchant
- âœ… **Social relationships**: dynamic links between agents
- âœ… **Decision-making**: reacts to internal state & environment

### LLM aspects
- âœ… **Ollama integration**: 30 % of decisions via local LLM
- âœ… **DeepSeek API**: generates final chronicles
- âœ… **Hybrid approach**: deterministic code + creative LLM
- âœ… **Context awareness**: LLM sees full world state

## ğŸ“Š Output
After execution you receive:

1. **world_state.json** â€“ Full simulation state:
   - Stats of all NPCs
   - Relationships between characters
   - Events per location
   - Daily logs

2. **chronicles.md** â€“ Epic fantasy-style chronicle (via DeepSeek)

## âš™ï¸ Configuration
In `config.py` you can tweak:
- `max_days` â€“ simulation length
- `llm_decision_chance` â€“ share of LLM decisions (0.3 = 30 %)
- `random_event_chance` â€“ frequency of random events
- `ollama_model` â€“ Ollama model to use

## ğŸ› ï¸ Troubleshooting

**Ollama not running:**
```bash
ollama serve
ollama list          # check models
ollama pull qwen2.5:3b # if model is missing
```

**DeepSeek error:**
- Verify API key in `config.py`
- Simulation works without DeepSeek (simpler chronicle)

**Python errors:**
- Requires Python 3.8+
- Make sure to install: `pip install ollama openai`

## ğŸ“ For Presentation

### Key Points
1. **Modular architecture** â€“ each component has a clear responsibility
2. **Hybrid AI** â€“ rule-based logic + LLM creativity
3. **Living simulation** â€“ NPCs age, die, build relationships
4. **Scalable** â€“ easy to add new NPCs or locations
5. **Practical demo** â€“ showcases AI Agent + LLM patterns

### Technology
- **Python 3.8+** â€“ primary language
- **Ollama** â€“ local LLM for decision making
- **DeepSeek API** â€“ powerful LLM for chronicles
- **JSON** â€“ state persistence
- **Async/Await** â€“ efficient LLM interaction